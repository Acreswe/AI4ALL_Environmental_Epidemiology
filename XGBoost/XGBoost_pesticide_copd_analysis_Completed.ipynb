{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy._core.defchararray import count\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY7XA-gAG1Wu",
        "outputId": "2178a200-ebbb-4794-f2a1-71a63edae87c"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "df_pesticides2 = pd.read_csv('Datasets/historical_data_2000_2022_filtered.csv')\n",
        "df_confounders = pd.read_csv('Datasets/copd_aqi_poverty_demographics.csv')\n",
        "df_population = pd.read_csv('Datasets/Population_Census_Numbers_2000_2025.csv')\n",
        "\n",
        "\n",
        "print(f'Pesticides: {df_pesticides2.columns.tolist()}')\n",
        "print(f'Confounders: {df_confounders.columns.tolist()}')\n",
        "\n",
        "print(f'\\nPesticide shape: {df_pesticides2.shape}')\n",
        "print(f'Confounders shape: {df_confounders.shape}')\n",
        "\n",
        "print(f'\\nPesticide yrs: {df_pesticides2['YEAR'].min()}--{df_pesticides2['YEAR'].max()} ')\n",
        "print(f'Confounders yrs: {df_confounders['Year'].min()}--{df_confounders['Year'].max()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvVmr6cms6fi",
        "outputId": "f785f6a0-f40e-4f56-f870-9d40d22873de"
      },
      "outputs": [],
      "source": [
        "#Data Standardization\n",
        "\n",
        "df_pesticides2.columns = map(str.lower, df_pesticides2.columns)\n",
        "df_confounders.columns = map(str.lower, df_confounders.columns)\n",
        "df_pesticides2 = df_pesticides2.rename(columns={'county_name': 'county', 'total_lbs_ai': 'total_pesticide_lbs'})\n",
        "df_confounders = df_confounders.rename(columns={'counties': 'county'})\n",
        "df_pesticides2['county'] = df_pesticides2['county'].replace('Tuolomne','Tuolumne')\n",
        "df_confounders['county'] = df_confounders['county'].replace('Tuolomne','Tuolumne')\n",
        "df_pesticides2['county'] = df_pesticides2['county'].str.lower()\n",
        "df_confounders['county'] = df_confounders['county'].str.lower()\n",
        "df_pesticides2['county'] = df_pesticides2['county'].str.strip()\n",
        "df_confounders['county'] = df_confounders['county'].str.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_confounders['median aqi'] = df_confounders.groupby('county')['median aqi'].transform(\n",
        "    lambda x: x.fillna(x.mean())\n",
        ")\n",
        "df_confounders['median aqi'] = df_confounders['median aqi'].fillna(\n",
        "    df_confounders['median aqi'].mean()\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "pesticide_counties = set(df_pesticides2['county'].unique())\n",
        "confounding_counties = set(df_confounders['county'].unique())\n",
        "county_assessment = pesticide_counties - confounding_counties\n",
        "\n",
        "print(f'\\nCounties not in one or the other: {county_assessment}')\n",
        "print(f'\\nCounties to be excluded: {county_assessment}')\n",
        "print(f'Overlapping counties: {len(pesticide_counties & confounding_counties)}')\n",
        "print(f'\\nPesticides: {df_pesticides2.columns.tolist()}')\n",
        "print(f'Confounders: {df_confounders.columns.tolist()}')\n",
        "print(f'\\nNulls for pesticide data: {df_pesticides2.isnull().sum()}')\n",
        "print(f'\\nNulls for confounders data: {df_confounders.isnull().sum()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Qas-RDhzwbme",
        "outputId": "30b77a66-8e2e-4ffb-e066-85ac00ffae84"
      },
      "outputs": [],
      "source": [
        "#Population Data\n",
        "df_population = df_population.rename(columns={'County': 'county'})\n",
        "\n",
        "population_long = df_population.melt(\n",
        "    id_vars=['county'],\n",
        "    var_name='date_str',\n",
        "    value_name='total_population'\n",
        ")\n",
        "\n",
        "def year_rewrite(date_str):\n",
        "  year_num = int(date_str.split('/')[-1])\n",
        "\n",
        "  if year_num >= 1900:\n",
        "    return year_num\n",
        "  elif year_num <= 25:\n",
        "    return 2000 + year_num\n",
        "  else:\n",
        "    return 1900 + year_num\n",
        "\n",
        "population_long['year'] = population_long['date_str'].apply(year_rewrite)\n",
        "\n",
        "population_long2 = population_long.drop(columns=['date_str'])\n",
        "\n",
        "population_long2['total_population'] = population_long2['total_population'].str.replace('\\t','')\n",
        "population_long2['total_population'] = population_long2['total_population'].str.replace(',','')\n",
        "population_long2['total_population'] = population_long2['total_population'].astype(float)\n",
        "population_long2['county'] = population_long2['county'].str.lower()\n",
        "population_long2['county'] = population_long2['county'].str.strip()\n",
        "\n",
        "\n",
        "print(f'\\nPopulation shape: {population_long2.shape}')\n",
        "print('\\nCounties:', population_long2['county'].nunique())\n",
        "population_long2.head(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_FoLvpuDjSt",
        "outputId": "9f7aa000-953a-4786-c6a5-242702f83ab8"
      },
      "outputs": [],
      "source": [
        "# Aggregating Pesticide Data by County-Year\n",
        "\n",
        "rows_by_county_year = df_pesticides2.groupby(['year','county']).size().head(6)\n",
        "print(rows_by_county_year)\n",
        "\n",
        "df_pesticides2 = df_pesticides2[(df_pesticides2['year'] >= 2000) & (df_pesticides2['year'] <= 2022)]\n",
        "df_confounders = df_confounders[(df_confounders['year'] >= 2000) & (df_confounders['year'] <= 2022)]\n",
        "\n",
        "\n",
        "pesticide_overall = df_pesticides2.groupby(['county', 'year']).agg({\n",
        "    'total_pesticide_lbs': 'sum',\n",
        "    'total_acres_treated': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "\n",
        "\n",
        "print(f'Total observations: {len(pesticide_overall)}')\n",
        "print(f'Shape: {pesticide_overall.shape}')\n",
        "print(f'Year range: {pesticide_overall['year'].min()} - {pesticide_overall['year'].max()}')\n",
        "print(f'Counties: {pesticide_overall['county'].nunique()}')\n",
        "print('\\nFirst 10 rows:')\n",
        "print(pesticide_overall.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVEo39ddMb-1",
        "outputId": "6542f9cc-e48f-4a42-9cc3-1033bbd8807b"
      },
      "outputs": [],
      "source": [
        "#Normalizing Pesticide data by population\n",
        "\n",
        "population_long2 = population_long2[(population_long2['year'] >= 2000) & (population_long2['year'] <= 2022)]\n",
        "\n",
        "pesticide_overall_merged = pesticide_overall.merge(population_long2,on=['county','year'],how='left')\n",
        "\n",
        "pesticide_overall_merged['total_pesticide_lbs_per_100k'] = ((pesticide_overall_merged['total_pesticide_lbs']/pesticide_overall_merged['total_population'])*100000)\n",
        "pesticide_overall_merged['total_acres_treated_per_100k'] = ((pesticide_overall_merged['total_acres_treated']/pesticide_overall_merged['total_population'])*100000)\n",
        "\n",
        "\n",
        "pesticide_overall_merged_clean = pesticide_overall_merged.dropna(subset=['total_population'])\n",
        "print(f'Rows dropped: {len(pesticide_overall_merged) - len(pesticide_overall_merged_clean)}')\n",
        "\n",
        "print('\\nFinal summary statistics:')\n",
        "print(pesticide_overall_merged_clean[['total_pesticide_lbs_per_100k', 'total_acres_treated_per_100k']].describe())\n",
        "print(pesticide_overall_merged_clean.head(10))\n",
        "pesticide_overall_merged = pesticide_overall_merged_clean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "qGGTNwo5Ubk7",
        "outputId": "90dae27c-ee10-4797-9e44-273f7f8194ce"
      },
      "outputs": [],
      "source": [
        "#Creating Lag Features\n",
        "\n",
        "def lag_features(df, column, lag_years=[1, 2, 3, 5,10,15,20]):\n",
        "  df_merged_sorted = pesticide_overall_merged.sort_values(['county','year']).copy()\n",
        "\n",
        "  for col in column:\n",
        "    for lag in lag_years:\n",
        "      df_merged_sorted[f'{col}_lag{lag}'] = df_merged_sorted.groupby('county')[col].shift(lag)\n",
        "  return df_merged_sorted\n",
        "\n",
        "to_lag = ['total_pesticide_lbs_per_100k','total_acres_treated_per_100k']\n",
        "\n",
        "pesticides_with_lags = lag_features(pesticide_overall_merged, to_lag, lag_years=[1, 2, 3, 5, 10, 15, 20])\n",
        "\n",
        "\n",
        "print(f'Original columns: {len(pesticide_overall_merged.columns)}')\n",
        "print(f'Columns with lags: {len(pesticides_with_lags.columns)}')\n",
        "print(f'New lag columns added: {len(pesticides_with_lags.columns) - len(pesticide_overall_merged.columns)}')\n",
        "\n",
        "print(f'All columns: {pesticides_with_lags.columns.to_list()}')\n",
        "\n",
        "pesticides_with_lags.head(6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "m6FzJ20YW_X4",
        "outputId": "61094f23-9503-4ed0-ab18-79bc32b7673f"
      },
      "outputs": [],
      "source": [
        "#Creating cumulative Exposure Features\n",
        "\n",
        "def cumulative_features(df, column, windows=[3,5,10,15,20]):\n",
        "  df_copied = df.copy()\n",
        "\n",
        "  for col in column:\n",
        "    for window in windows:\n",
        "      df_copied[f'{col}_cumulative_sum{window}year'] = (df_copied.groupby('county')[col].rolling(window=window, min_periods=1).sum().reset_index(level=0, drop=True))\n",
        "      df_copied[f'{col}_cumulative_mean{window}year'] = (df_copied.groupby('county')[col].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True))\n",
        "  return df_copied\n",
        "\n",
        "\n",
        "to_accumulate = ['total_pesticide_lbs_per_100k','total_acres_treated_per_100k']\n",
        "\n",
        "final_pesticide = cumulative_features(pesticides_with_lags, to_accumulate, windows=[3,5,10,15,20])\n",
        "\n",
        "\n",
        "print(f'Columns before: {len(pesticides_with_lags.columns)}')\n",
        "print(f'Columns after: {len(final_pesticide.columns)}')\n",
        "print(f'New features added: {len(final_pesticide.columns) - len(pesticides_with_lags.columns)}')\n",
        "\n",
        "final_pesticide.head(6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd7sC8-ScrWC",
        "outputId": "c3a6831f-4226-428e-acd7-d0f8bd638dbd"
      },
      "outputs": [],
      "source": [
        "# Merging Pesticide Features with Confounders\n",
        "\n",
        "final_merged_with_confounders = df_confounders.merge(final_pesticide,on=['county','year'],how='inner')\n",
        "complete_dataset = final_merged_with_confounders\n",
        "\n",
        "\n",
        "county_coverage = complete_dataset.groupby('county')['year'].agg(['count', 'min', 'max'])\n",
        "county_coverage.columns = ['num_years', 'first_year', 'last_year']\n",
        "county_coverage = county_coverage.sort_values('num_years')\n",
        "\n",
        "print(f'County Coverage Summary:{county_coverage}')\n",
        "print(f'\\nCounties with complete data (23 years): {(county_coverage['num_years'] == 23).sum()}')\n",
        "print(f'Counties with partial data: {(county_coverage['num_years'] < 23).sum()}')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DisbaADxzZ0u",
        "outputId": "5cb6c946-c9f2-4431-c469-973590882995"
      },
      "outputs": [],
      "source": [
        "# Handling missing values\n",
        "\n",
        "complete_dataset_filtered = complete_dataset[complete_dataset['year'] >= 2005].copy()\n",
        "\n",
        "\n",
        "lag10_cols = [col for col in complete_dataset_filtered.columns if 'lag10' in col]\n",
        "lag15_cols = [col for col in complete_dataset_filtered.columns if 'lag15' in col]\n",
        "lag20_cols = [col for col in complete_dataset_filtered.columns if 'lag20' in col]\n",
        "complete_dataset_filtered = complete_dataset_filtered.drop(columns=lag20_cols)\n",
        "complete_dataset_filtered = complete_dataset_filtered.drop(columns=lag15_cols)\n",
        "complete_dataset_filtered = complete_dataset_filtered.drop(columns=lag10_cols)\n",
        "\n",
        "\n",
        "complete_dataset_cleaned = complete_dataset_filtered.dropna()\n",
        "print('Cleaned Dataset summarization')\n",
        "print(f'- Shape: {complete_dataset_cleaned.shape}')\n",
        "print(f'- Year range: {complete_dataset_cleaned['year'].min()} - {complete_dataset_cleaned['year'].max()}')\n",
        "print(f'- Counties: {complete_dataset_cleaned['county'].nunique()}')\n",
        "print(f'- Total features: {complete_dataset_cleaned.shape[1] - 3}')\n",
        "print(f'- Observations per feature: {len(complete_dataset_cleaned) / (complete_dataset_cleaned.shape[1] - 3):.1f}')\n",
        "print(complete_dataset_cleaned['copd_hospitalization_rate'].describe())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my-3eytyvuL0",
        "outputId": "b4295cfc-0ae0-4ded-985d-ac6fb81635c8"
      },
      "outputs": [],
      "source": [
        "#Validating Lag features\n",
        "\n",
        "county_counts = final_pesticide.groupby('county').size()\n",
        "sample_county = county_counts.idxmax()\n",
        "\n",
        "validation_sample = final_pesticide[final_pesticide['county'] == sample_county].sort_values('year')\n",
        "\n",
        "display_cols = ['year', 'total_pesticide_lbs_per_100k',\n",
        "                'total_pesticide_lbs_per_100k_lag1',\n",
        "                'total_pesticide_lbs_per_100k_lag5',\n",
        "                'total_pesticide_lbs_per_100k_lag10',\n",
        "                'total_pesticide_lbs_per_100k_lag20']\n",
        "\n",
        "print(validation_sample[display_cols].head(25).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEFZVd5N5htR",
        "outputId": "b6d54509-6ba3-4e4b-d225-df0ef92d9463"
      },
      "outputs": [],
      "source": [
        "# Feature Organization\n",
        "\n",
        "indentifiers = ['county','years']\n",
        "target = 'copd_hospitalization_rate'\n",
        "\n",
        "confounding_features = [\n",
        "    'median aqi',\n",
        "    'pct_under_18', 'pct_18_64', 'pct_65_plus', 'median_age',\n",
        "    'pct_ai/an', 'pct_asian', 'pct_black', 'pct_latino',\n",
        "    'pct_multi_race', 'pct_nh/pi', 'pct_white',\n",
        "    'poverty_allages_percent_est', 'median_household_income_est'\n",
        "]\n",
        "pesticide_features = ['total_pesticide_lbs', 'total_acres_treated',\n",
        "                 'total_population', 'total_pesticide_lbs_per_100k',\n",
        "                 'total_acres_treated_per_100k']\n",
        "\n",
        "pesticide_lag = [col for col in complete_dataset_cleaned.columns if 'lag' in col]\n",
        "pesticide_cumulative = [col for col in complete_dataset_cleaned.columns if 'cumulative' in col]\n",
        "\n",
        "\n",
        "features_to_drop = []\n",
        "sum_features = [col for col in complete_dataset_cleaned.columns if 'cumulative_sum' in col]\n",
        "features_to_drop.extend(sum_features)\n",
        "lag_to_drop = [col for col in complete_dataset_cleaned.columns if 'lag3' in col or 'lag5' in col]\n",
        "features_to_drop.extend(lag_to_drop)\n",
        "cum_mean_to_drop = [col for col in complete_dataset_cleaned.columns\n",
        "                    if any(x in col for x in ['cumulative_mean3year',\n",
        "                                               'cumulative_mean10year',\n",
        "                                               'cumulative_mean15year'])]\n",
        "features_to_drop.extend(cum_mean_to_drop)\n",
        "raw_to_drop = ['total_pesticide_lbs', 'total_acres_treated']\n",
        "features_to_drop.extend(raw_to_drop)\n",
        "complete_dataset_final = complete_dataset_cleaned.drop(columns=features_to_drop)\n",
        "\n",
        "\n",
        "print(f'Remaining: {[col for col in complete_dataset_final.columns if any(x in col for x in ['pesticide', 'acres', 'population'])]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaErcD3_-gFB",
        "outputId": "aaf841b8-6eec-439b-f5af-bf44eb72f75b"
      },
      "outputs": [],
      "source": [
        "# Data prep for XGBoost\n",
        "\n",
        "pesticide_features = ['total_population', 'total_pesticide_lbs_per_100k',\n",
        "                      'total_acres_treated_per_100k', 'total_pesticide_lbs_per_100k_lag1',\n",
        "                      'total_pesticide_lbs_per_100k_lag2', 'total_acres_treated_per_100k_lag1',\n",
        "                      'total_acres_treated_per_100k_lag2',\n",
        "                      'total_pesticide_lbs_per_100k_cumulative_mean5year',\n",
        "                      'total_pesticide_lbs_per_100k_cumulative_mean20year',\n",
        "                      'total_acres_treated_per_100k_cumulative_mean5year',\n",
        "                      'total_acres_treated_per_100k_cumulative_mean20year']\n",
        "\n",
        "confounders = ['median aqi', 'pct_under_18', 'pct_18_64', 'pct_65_plus', 'median_age',\n",
        "               'pct_ai/an', 'pct_asian', 'pct_black', 'pct_latino', 'pct_multi_race',\n",
        "               'pct_nh/pi', 'pct_white', 'poverty_allages_percent_est',\n",
        "               'median_household_income_est']\n",
        "\n",
        "all_features = pesticide_features + confounders\n",
        "\n",
        "X = complete_dataset_final[all_features]\n",
        "Y = complete_dataset_final['copd_hospitalization_rate']\n",
        "\n",
        "print(f'X shape: {X.shape}')\n",
        "print(f'Y shape: {Y.shape}')\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    complete_dataset_final,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "X_train = train_df[all_features].values\n",
        "y_train = train_df['copd_hospitalization_rate'].values\n",
        "\n",
        "X_test = test_df[all_features].values\n",
        "y_test = test_df['copd_hospitalization_rate'].values\n",
        "\n",
        "print(f'\\nTarget variable (COPD rate) statistics:')\n",
        "print(f' Train - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}, Range: [{y_train.min():.2f}, {y_train.max():.2f}]')\n",
        "print(f' Test  - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}, Range: [{y_test.min():.2f}, {y_test.max():.2f}]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpU2C1RSVMI6",
        "outputId": "f9c57c52-8af1-4515-e89a-a435c8393dd4"
      },
      "outputs": [],
      "source": [
        "# Baseline XGBoost Model Training\n",
        "\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3,\n",
        "    n_estimators=50,\n",
        "    min_child_weight=10,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_alpha=1.0,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(X_train,y_train, verbose=False)\n",
        "y_train_prediction = model.predict(X_train)\n",
        "y_test_prediction = model.predict(X_test)\n",
        "\n",
        "rmse_training = np.sqrt(mean_squared_error(y_train,y_train_prediction))\n",
        "mae_training = (mean_absolute_error(y_train,y_train_prediction))\n",
        "r2_score_training = r2_score(y_train,y_train_prediction)\n",
        "\n",
        "rmse_testing = np.sqrt(mean_squared_error(y_test,y_test_prediction))\n",
        "mae_testing = mean_absolute_error(y_test,y_test_prediction)\n",
        "r2_score_testing = r2_score(y_test,y_test_prediction)\n",
        "\n",
        "\n",
        "r2_diff = r2_score_training - r2_score_testing\n",
        "print(f'Train R² - Test R² = {r2_diff:.4f}')\n",
        "\n",
        "if r2_diff > 0.2:\n",
        "  print(f'\\nOverfitting Detected (R² gap: {r2_diff:.4f})')\n",
        "elif r2_diff > 0.1:\n",
        "  print(f'Moderate Overfitting (R² gap: {r2_diff:.4f})')\n",
        "else:\n",
        "  print(f'Minimal overfitting (R² gap: {r2_diff:.4f})')\n",
        "\n",
        "\n",
        "naive_rmse = np.sqrt(mean_squared_error(y_test, [y_train.mean()]*len(y_test)))\n",
        "improvement = (naive_rmse - rmse_testing) / naive_rmse * 100\n",
        "\n",
        "print(f'\\nBaseline comparison:')\n",
        "print(f'Naive (predict train mean): RMSE ={naive_rmse:.2f}')\n",
        "print(f'XGBoost: RMSE = {rmse_testing:.2f}')\n",
        "print(f'Improvement: {improvement:.1f}%')\n",
        "\n",
        "print('\\nTraining set performance:')\n",
        "print(f' RMSE: {rmse_training:.2f}')\n",
        "print(f' MAE:  {mae_training:.2f}')\n",
        "print(f' R²: {r2_score_training:.4f}')\n",
        "\n",
        "print('\\nTest set performance:')\n",
        "print(f' RMSE: {rmse_testing:.2f}')\n",
        "print(f' MAE: {mae_testing:.2f}')\n",
        "print(f' R²: {r2_score_testing:.4f}')\n",
        "\n",
        "print(f'\\nModel Performance Summary:')\n",
        "if r2_score_testing < 0:\n",
        "    print(f'Test RÂ² is negative ({r2_score_testing:.4f})')\n",
        "    print(f'Model performs worse than predicting the mean')\n",
        "    print(f'Cause: Distribution shift between train/test')\n",
        "elif r2_score_testing < 0.3:\n",
        "    print(f'Test R² is low ({r2_score_testing:.4f})')\n",
        "    print(f'Weak predictive power')\n",
        "else:\n",
        "    print(f'Test R² is {r2_score_testing:.4f}')\n",
        "    print(f'Explains {r2_score_testing*100:.1f}% of variance')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wfs53DqfAw9",
        "outputId": "a973773e-d8e8-43ee-cd8e-07f7879c262e"
      },
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "\n",
        "feat_importance = model.feature_importances_\n",
        "df_importance = pd.DataFrame({'feature': all_features, 'importance': feat_importance}).sort_values('importance', ascending=False)\n",
        "\n",
        "for idx, row in df_importance.head(15).iterrows():\n",
        "    if row['feature'] in pesticide_features:\n",
        "        category = '[PESTICIDE]'\n",
        "    else:\n",
        "        category = '[CONFOUNDER]'\n",
        "\n",
        "    print(f'{row['feature']:50s} {category:13s} {row['importance']:.4f}')\n",
        "\n",
        "pesticide_importance = df_importance[df_importance['feature'].isin(pesticide_features)]['importance'].sum()\n",
        "confounder_importance = df_importance[df_importance['feature'].isin(confounders)]['importance'].sum()\n",
        "total = pesticide_importance + confounder_importance\n",
        "\n",
        "\n",
        "print(f'Pesticide features:  {pesticide_importance:.3f} ({pesticide_importance/total*100:.1f}%)')\n",
        "print(f'Confounder features: {confounder_importance:.3f} ({confounder_importance/total*100:.1f}%)')\n",
        "\n",
        "print('\\nPesticide contribution to COPD prediction:')\n",
        "if pesticide_importance/total > 0.30:\n",
        "  print(f'Strong evidence: Pesticides account for {pesticide_importance/total*100:.1f}% of predictive power')\n",
        "elif pesticide_importance/total > 0.15:\n",
        "  print(f'Moderate evidence: Pesticides account for {pesticide_importance/total*100:.1f}% of predictive power')\n",
        "elif pesticide_importance/total > 0.05:\n",
        "  print(f'Weak evidence: Pesticides account for {pesticide_importance/total*100:.1f}% of predictive power')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
